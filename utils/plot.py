import matplotlib.pyplot as plt
import torch
import numpy as np
import seaborn as sns
import os
import sys
sys.path.append('./')
from config.cfgs import cfgs


def plot_loss_acc(model, steps=50):
    train_loss = np.load(f'{cfgs["save_data_path"]}/{model}_train_loss_{steps}.npy')
    val_loss = np.load(f'{cfgs["save_data_path"]}/{model}_val_loss_{steps}.npy')
    train_acc = np.load(f'{cfgs["save_data_path"]}/{model}_train_acc_{steps}.npy')
    val_acc = np.load(f'{cfgs["save_data_path"]}/{model}_val_acc_{steps}.npy')
    
    plt.figure(figsize=(8, 6),dpi=200)
    plt.plot(range(1,len(train_loss)+1), train_loss, label='Training loss')
    plt.plot(range(1,len(val_loss)+1), val_loss, label='Testing loss')
    plt.legend()
    plt.savefig(f'{cfgs["save_img_path"]}/{model}_loss_{steps}.png')
    plt.close()

    plt.figure(figsize=(8, 6),dpi=200)
    plt.plot(range(1,len(train_acc)+1), train_acc, label='Training accuracy')
    plt.plot(range(1,len(val_acc)+1), val_acc, label='Testing accuracy')
    plt.legend()
    plt.savefig(f'{cfgs["save_img_path"]}/{model}_acc_{steps}.png')
    plt.close()

def plot_conf_matrix(fn):
    conf_matrix = np.load(f'{cfgs["save_data_path"]}/{fn}_conf_matrix.npy')
    conf_matrix = conf_matrix / np.sum(conf_matrix, axis=1)
    class_names = os.listdir(cfgs['malimg_path'])
    plt.figure(figsize=(16, 16))
    sns.heatmap(conf_matrix, annot=True, fmt='.2f', cmap='Blues', xticklabels=class_names, yticklabels=class_names)
    plt.xlabel('Predicted Labels')
    plt.ylabel('True Labels')
    plt.title('Confusion Matrix')
    plt.savefig(f"{cfgs['save_img_path']}/{fn}_conf_matrix.png")
    plt.close()

def main(steps=50):
    plot_loss_acc('vgg16', steps)
    plot_loss_acc('resnet50', steps)
    plot_loss_acc('googlenet', steps)
    plot_loss_acc('densenet121', steps)
    plot_loss_acc('shufflenet', steps)
    plot_conf_matrix('vgg16_train')
    plot_conf_matrix('vgg16_val')
    plot_conf_matrix('resnet50_train')
    plot_conf_matrix('resnet50_val')
    plot_conf_matrix('googlenet_train')
    plot_conf_matrix('googlenet_val')
    plot_conf_matrix('densenet121_train')
    plot_conf_matrix('densenet121_val')
    plot_conf_matrix('shufflenet_train')
    plot_conf_matrix('shufflenet_val')
    plot_conf_matrix('bayesian_combination')
    plot_conf_matrix('stacking')

    plt.figure(figsize=(8, 6), dpi=200)
    for model in ['vgg16', 'resnet50', 'googlenet', 'densenet121', 'shufflenet']:
        train_loss = np.load(f'{cfgs["save_data_path"]}/{model}_train_loss_{steps}.npy')
        val_loss = np.load(f'{cfgs["save_data_path"]}/{model}_val_loss_{steps}.npy')
        
        plt.plot(range(1,len(train_loss)+1), train_loss, label=f'{model} Train')
        plt.plot(range(1,len(val_loss)+1), val_loss, label=f'{model} Test')
    plt.xlabel('Epochs')
    plt.ylabel('Loss')
    plt.xticks(np.arange(0, steps+1, step=5))
    plt.legend()
    plt.savefig(f'{cfgs["save_img_path"]}/all_loss_{steps}.png')
    plt.close()

    plt.figure(figsize=(8, 6), dpi=200)
    for model in ['vgg16', 'resnet50', 'googlenet', 'densenet121', 'shufflenet']:
        train_loss = np.load(f'{cfgs["save_data_path"]}/{model}_train_acc_{steps}.npy')
        val_loss = np.load(f'{cfgs["save_data_path"]}/{model}_val_acc_{steps}.npy')
        
        plt.plot(range(1,len(train_loss)+1), train_loss, label=f'{model} Train')
        plt.plot(range(1,len(val_loss)+1), val_loss, label=f'{model} Test')
    plt.xlabel('Epochs')
    plt.ylabel('Accuracy')
    plt.xticks(np.arange(0, steps+1, step=5))
    plt.legend()
    plt.savefig(f'{cfgs["save_img_path"]}/all_acc_{steps}.png')
    plt.close()

    # ! Use validation dataset here
    vgg16_conf_matrix = np.load(f'{cfgs["save_data_path"]}/vgg16_val_conf_matrix.npy')
    resnet50_conf_matrix = np.load(f'{cfgs["save_data_path"]}/resnet50_val_conf_matrix.npy')
    googlenet_conf_matrix = np.load(f'{cfgs["save_data_path"]}/googlenet_val_conf_matrix.npy')
    densenet121_conf_matrix = np.load(f'{cfgs["save_data_path"]}/densenet121_val_conf_matrix.npy')
    shufflenet_conf_matrix = np.load(f'{cfgs["save_data_path"]}/shufflenet_val_conf_matrix.npy')
    stacking_conf_matrix = np.load(f'{cfgs["save_data_path"]}/stacking_conf_matrix.npy')
    bayesian_combination_conf_matrix = np.load(f'{cfgs["save_data_path"]}/bayesian_combination_conf_matrix.npy')
    distribution_summation_conf_matrix = np.load(f'{cfgs["save_data_path"]}/distribution_summation_conf_matrix.npy')
    majority_voting_conf_matrix = np.load(f'{cfgs["save_data_path"]}/majority_voting_conf_matrix.npy')

    vgg16_conf_matrix = vgg16_conf_matrix / vgg16_conf_matrix.sum(axis=1, keepdims=True)
    resnet50_conf_matrix = resnet50_conf_matrix / resnet50_conf_matrix.sum(axis=1, keepdims=True)
    googlenet_conf_matrix = googlenet_conf_matrix / googlenet_conf_matrix.sum(axis=1, keepdims=True)
    densenet121_conf_matrix = densenet121_conf_matrix / densenet121_conf_matrix.sum(axis=1, keepdims=True)
    shufflenet_conf_matrix = shufflenet_conf_matrix / shufflenet_conf_matrix.sum(axis=1, keepdims=True)
    stacking_conf_matrix = stacking_conf_matrix / stacking_conf_matrix.sum(axis=1, keepdims=True)
    bayesian_combination_conf_matrix = bayesian_combination_conf_matrix / bayesian_combination_conf_matrix.sum(axis=1, keepdims=True)
    distribution_summation_conf_matrix = distribution_summation_conf_matrix / distribution_summation_conf_matrix.sum(axis=1, keepdims=True)
    majority_voting_conf_matrix = majority_voting_conf_matrix / majority_voting_conf_matrix.sum(axis=1, keepdims=True)

    vgg16_probs = torch.Tensor([vgg16_conf_matrix[i,i] for i in range(len(vgg16_conf_matrix))])
    resnet50_probs = torch.Tensor([resnet50_conf_matrix[i,i] for i in range(len(resnet50_conf_matrix))])
    googlenet_probs = torch.Tensor([googlenet_conf_matrix[i, i] for i in range(len(googlenet_conf_matrix))])
    densenet121_probs = torch.Tensor([densenet121_conf_matrix[i, i] for i in range(len(densenet121_conf_matrix))])
    shufflenet_probs = torch.Tensor([shufflenet_conf_matrix[i, i] for i in range(len(shufflenet_conf_matrix))])
    stacking_conf_probs = torch.Tensor([stacking_conf_matrix[i, i] for i in range(len(stacking_conf_matrix))])
    bayesian_combination_conf_probs = torch.Tensor([bayesian_combination_conf_matrix[i, i] for i in range(len(bayesian_combination_conf_matrix))])
    distribution_summation_conf_probs = torch.Tensor([distribution_summation_conf_matrix[i, i] for i in range(len(distribution_summation_conf_matrix))])
    majority_voting_conf_probs = torch.Tensor([majority_voting_conf_matrix[i, i] for i in range(len(majority_voting_conf_matrix))])

    class_names = os.listdir(cfgs['malimg_path'])
    plt.figure(figsize=(18, 12), dpi=200)
    plt.plot(vgg16_probs,marker='o',label='VGG16')
    plt.plot(resnet50_probs,marker='v',label='ResNet50')
    plt.plot(googlenet_probs,marker='^',label='GoogLeNet')
    plt.plot(densenet121_probs,marker='<',label='DenseNet121')
    plt.plot(shufflenet_probs,marker='>',label='ShuffleNet')
    plt.plot(stacking_conf_probs,marker='x',label='Stacking')
    plt.plot(bayesian_combination_conf_probs,marker='d',label='Bayesian Combination')
    plt.plot(distribution_summation_conf_probs,marker='*',label='Distribution Summation')
    plt.plot(majority_voting_conf_probs,marker='1',label='Majority Voting')
    # print(class_names)
    # print(vgg16_probs.tolist())
    # print(resnet50_probs.tolist())
    # print(googlenet_probs.tolist())
    # print(densenet121_probs.tolist())
    # print(shufflenet_probs.tolist())
    # print(stacking_conf_probs.tolist())
    # print(bayesian_combination_conf_probs.tolist())
    # print(distribution_summation_conf_probs.tolist())
    # print(majority_voting_conf_probs.tolist())
    plt.xlabel('Classes')
    plt.ylabel('Accuracy')
    plt.xticks(range(len(class_names)), class_names, rotation=90)
    plt.legend()
    plt.savefig(f'{cfgs["save_img_path"]}/acc_vs_classes.png')
    plt.close()

if __name__ == '__main__':
    main(steps=50)