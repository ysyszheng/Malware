'''load data from image dir for training and validation'''
import sys
sys.path.append('./')
import torch
from torchvision import datasets, transforms
from torch.utils.data import DataLoader, random_split
from PIL import Image
from utils import fix_seed
from config.cfgs import cfgs
Image.MAX_IMAGE_PIXELS = None


def get_dataset(data_dir, seed, train_ratio=0.7):
    fix_seed(seed)
    data_transforms = {
        'train': transforms.Compose([
            transforms.Resize((224, 224)),
            transforms.ToTensor(),
            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])
        ]),
    }

    images_dataset = datasets.ImageFolder(data_dir, transform=data_transforms['train'])
    train_size = int(train_ratio * len(images_dataset))
    val_size = len(images_dataset) - train_size
    train_dataset, val_dataset = random_split(images_dataset, [train_size, val_size])

    return train_dataset, val_dataset

def get_dataloaders(train_dataset, val_dataset, seed, batch_size=32, num_workers=4):
    fix_seed(seed)

    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=num_workers)
    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=num_workers)

    return train_loader, val_loader


if __name__ == '__main__':
    train_dataset, val_dataset = get_dataset(cfgs['malimg_path'], cfgs['seed'], train_ratio=cfgs['split_ratio'])
    train_loader, val_loader = get_dataloaders(train_dataset, val_dataset, cfgs['seed'], cfgs['batch_size'], cfgs['num_workers'])
    torch.save(train_dataset, f'{cfgs["save_data_path"]}/train_dataset.pth')
    torch.save(val_dataset, f'{cfgs["save_data_path"]}/val_dataset.pth')
    torch.save(train_loader, f'{cfgs["save_data_path"]}/train_loader.pth')
    torch.save(val_loader, f'{cfgs["save_data_path"]}/val_loader.pth')
