from config.config import device, config
from models.SVMModel import SVM
from models.VGGModel import VGG16
from models.ResNetModel import ResNet50
from utils.pca import pca
from torchvision import transforms
import torch
import torchvision
from torch.utils.data import TensorDataset, DataLoader, random_split
from PIL import Image
Image.MAX_IMAGE_PIXELS = None


def train_cnn(train_loader, model, optimizer, criterion, num_epochs):
    model.train()
    for epoch in range(num_epochs):
        running_loss = 0.0
        for _, (inputs, labels) in enumerate(train_loader, 0):
            inputs, labels = inputs.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(inputs)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            running_loss += loss.item()
        print('Epoch [%d]/[%d], loss: %.3f' %
              (epoch + 1, num_epochs, running_loss / len(train_loader)))
    print('Finished Training')


def train_svm():
    pass  # TODO: how to train


def predict(inputs, model):
    model.eval()
    model.to(device)
    inputs.to(device)
    with torch.no_grad:
        outputs = model(inputs)  # TODO: shape of outputs
    pr = torch.nn.functional.softmax(outputs, dim=1)  # TODO: dim = ?
    return pr


if __name__ == "__main__":
    # transform and augment
    data_transforms = {  # TODO: build diff transform
        'train': transforms.Compose([
            transforms.Resize(256),
            transforms.CenterCrop(224),
            transforms.ToTensor(),
            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[
                0.229, 0.224, 0.225]),
        ]),
        'val': transforms.Compose([
            transforms.Resize(256),
            transforms.CenterCrop(224),
            transforms.ToTensor(),
            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])
        ]),
    }

    # config info
    batch_size = config['batch_size']
    learning_rate = config['learning_rate']
    alpha = config['momentum']
    lambd = config['weight_decay']
    num_epochs = config['num_epochs']
    num_workers = config['num_workers']
    num_class = config['num_class']
    split_rate = config['split_rate']
    data_path = config['img_path']

    # dataset and dataloader
    dataset = torchvision.datasets.ImageFolder(
        root=data_path, transform=data_transforms['train'])  # TODO: diff transform for diff model?

    train_size = int(config['split_rate'] * len(dataset))
    val_size = len(dataset) - train_size
    train_dataset, val_dataset = random_split(
        dataset, [train_size, val_size])

    train_loader = DataLoader(
        train_dataset, batch_size=batch_size, shuffle=True, num_workers=num_workers)
    val_loader = DataLoader(
        val_dataset, batch_size=batch_size, num_workers=num_workers)

    # model define
    svm_model = SVM
    vgg_model = VGG16(num_class)
    resnet_model = ResNet50(num_class)

    # get SVM feature
    for mode in ['train', 'val']:
        loader = train_loader if mode == 'train' else val_loader

        vgg_feat_ds = TensorDataset()
        resnet_feat_ds = TensorDataset()
        combined_feat_ds = TensorDataset()

        for _, (inputs, labels) in enumerate(loader, 0):
            vgg_model.eval()
            resnet_model.eval()
            vgg_model.to(device)
            resnet_model.to(device)
            inputs.to(device)

            with torch.no_grad():
                vgg_feat_new = vgg_model(inputs)  # TODO: get fc2 layer feat
                # TODO: get avg_pool layer feat
                resnet_feat_new = resnet_model(inputs)
            combined_feat_new = torch.cat(
                (vgg_feat_new, resnet_feat_new), dim=1)

            vgg_feat_old, vgg_labels_old = vgg_feat_ds.tensors
            resnet_feat_old, resnet_labels_old = resnet_feat_ds.tensors
            combined_feat_old, combined_labels_old = combined_feat_ds.tensors

            vgg_feat = torch.cat((vgg_feat_old, vgg_feat_new), dim=0)
            vgg_labels = torch.cat((vgg_labels_old, labels), dim=0)
            resnet_feat = torch.cat((resnet_feat_old, resnet_feat_new), dim=0)
            resnet_labels = torch.cat((resnet_labels_old, labels), dim=0)
            combined_feat = torch.cat(
                (combined_feat_old, combined_feat_new), dim=0)
            combined_labels = torch.cat((combined_labels_old, labels), dim=0)

            resnet_feat_ds = TensorDataset(resnet_feat, resnet_labels)
            vgg_feat_ds = TensorDataset(vgg_feat, vgg_labels)
            combined_feat_ds = TensorDataset(combined_feat, combined_labels)

        # PCA 90%
        vgg_feat_old, vgg_labels_old = vgg_feat_ds.tensors
        resnet_feat_old, resnet_labels_old = resnet_feat_ds.tensors
        combined_feat_old, combined_labels_old = combined_feat_ds.tensors

        vgg_feat_new = pca(vgg_feat_old, 0.9)
        resnet_feat_new = pca(resnet_feat_old, 0.9)
        combined_feat_new = pca(combined_feat_old, 0.9)

        resnet_feat_ds = TensorDataset(resnet_feat_new, resnet_labels_old)
        vgg_feat_ds = TensorDataset(vgg_feat_new, vgg_labels_old)
        combined_feat_ds = TensorDataset(
            combined_feat_new, combined_labels_old)

        if mode == 'train':
            vgg_feat_train_ld = DataLoader(
                vgg_feat_ds, batch_size=batch_size, shuffle=True, num_workers=num_workers)
            resnet_feat_train_ld = DataLoader(
                resnet_feat_ds, batch_size=batch_size, shuffle=True, num_workers=num_workers)
            combined_feat_train_ld = DataLoader(
                combined_feat_ds, batch_size=batch_size, shuffle=True, num_workers=num_workers)
        elif mode == 'val':
            vgg_feat_val_ld = DataLoader(
                vgg_feat_ds, batch_size=batch_size, num_workers=num_workers)
            resnet_feat_val_ld = DataLoader(
                resnet_feat_ds, batch_size=batch_size, num_workers=num_workers)
            combined_feat_val_ld = DataLoader(
                combined_feat_ds, batch_size=batch_size, num_workers=num_workers)

    # train SVM
    # TODO:

    # train CNN
    criterion = torch.nn.CrossEntropyLoss()
    optimizer_vgg = torch.optim.SGD(
        vgg_model.parameters(), lr=learning_rate, momentum=alpha, weight_decay=lambd)
    optimizer_resnet = torch.optim.SGD(
        resnet_model.parameters(), lr=learning_rate, momentum=alpha, weight_decay=lambd)

    train_cnn(train_loader, vgg_model, optimizer_vgg, criterion, num_epochs)
    train_cnn(train_loader, resnet_model,
              optimizer_resnet, criterion, num_epochs)

    # eval
    vgg_model.eval()
    for _, (inputs, labels) in enumerate(val_loader, 0):
        pass  # TODO:
