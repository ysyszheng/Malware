from config.config import device, data_transforms, config
from models.SVMModel import OvASVM
from models.VGGModel import VGG16
from models.ResNetModel import ResNet50
from utils.pca import pca
import torch
import numpy as np
import pdb
import torchvision
from torch.utils.data import TensorDataset, DataLoader, random_split
from torch.nn.functional import softmax
from PIL import Image
from tqdm import tqdm
import itertools
Image.MAX_IMAGE_PIXELS = None

# store features extracted from cnn layers
vgg_feat_list = []
resnet_feat_list = []


def vgg_hook(module, input, output):
    vgg_feat_list.append(output)


def resnet_hook(module, input, output):
    resnet_feat_list.append(output)


def train_cnn(train_loader, model, optimizer, criterion, num_epochs):
    model.train()
    model.to(device)
    for epoch in range(num_epochs):
        running_loss = 0.0
        for (inputs, labels) in tqdm(train_loader):
            inputs, labels = inputs.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(inputs)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            running_loss += loss.item()
            torch.cuda.empty_cache()
        print('Epoch [%d]/[%d], loss: %.3f' %
              (epoch + 1, num_epochs, running_loss / len(train_loader)))
    print('Finished Training')


def predict(inputs, model):
    model.eval()
    model.to(device)
    inputs = inputs.to(device)
    with torch.no_grad():
        outputs = model(inputs)
    pr = softmax(outputs, dim=1)
    return pr


# def main():
if __name__ == "__main__":
    # config info
    batch_size = config['batch_size']
    learning_rate = config['learning_rate']
    alpha = config['momentum']
    lambd = config['weight_decay']
    num_epochs = config['num_epochs']
    num_workers = config['num_workers']
    num_class = config['num_class']
    split_rate = config['split_rate']
    data_path = config['img_path']

    # dataset and dataloader
    dataset = torchvision.datasets.ImageFolder(
        root=data_path, transform=data_transforms['train'])  # TODO: diff transform for diff model?

    train_size = int(config['split_rate'] * len(dataset))
    val_size = len(dataset) - train_size
    train_dataset, val_dataset = random_split(
        dataset, [train_size, val_size])

    train_loader = DataLoader(
        train_dataset, batch_size=batch_size, shuffle=True, num_workers=num_workers)
    val_loader = DataLoader(
        val_dataset, batch_size=batch_size, num_workers=num_workers)

    # model define
    vgg_model = VGG16(num_class)
    resnet_model = ResNet50(num_class)
    vgg_svm_model = OvASVM(num_class)
    resnet_svm_model = OvASVM(num_class)
    combined_svm_model = OvASVM(num_class)

    # # register hook
    # vgg_handle = vgg_model.vgg.classifier[4].register_forward_hook(
    #     vgg_hook)  # TODO: is this FC2 layer? before or after relu?
    # resnet_handle = resnet_model.resnet.avgpool.register_forward_hook(
    #     resnet_hook)

    # # get SVM feature
    # print('Start getting SVM features...')
    # vgg_model.eval()
    # resnet_model.eval()
    # vgg_model.to(device)
    # resnet_model.to(device)
    
    # for mode in ['train', 'val']:
    #     print(f'mode: {mode}')
    #     loader = train_loader if mode == 'train' else val_loader


    #     for i, (inputs, labels) in enumerate(tqdm(loader)):
    #         inputs = inputs.to(device)

    #         with torch.no_grad():
    #             _ = vgg_model(inputs)
    #             vgg_feat_new = vgg_feat_list.pop().squeeze()
    #             _ = resnet_model(inputs)
    #             resnet_feat_new = resnet_feat_list.pop().squeeze()

    #         combined_feat_new = torch.cat(
    #             (vgg_feat_new, resnet_feat_new), dim=1)

    #         if i == 0:
    #             vgg_feat, vgg_labels = vgg_feat_new, labels
    #             resnet_feat, resnet_labels = resnet_feat_new, labels
    #             combined_feat, combined_labels = combined_feat_new, labels
    #         else:
    #             vgg_feat_old, vgg_labels_old = vgg_feat_ds.tensors
    #             resnet_feat_old, resnet_labels_old = resnet_feat_ds.tensors
    #             combined_feat_old, combined_labels_old = combined_feat_ds.tensors

    #             vgg_feat = torch.cat((vgg_feat_old, vgg_feat_new), dim=0)
    #             resnet_feat = torch.cat(
    #                 (resnet_feat_old, resnet_feat_new), dim=0)
    #             combined_feat = torch.cat(
    #                 (combined_feat_old, combined_feat_new), dim=0)

    #             vgg_labels = torch.cat((vgg_labels_old, labels), dim=0)
    #             resnet_labels = torch.cat((resnet_labels_old, labels), dim=0)
    #             combined_labels = torch.cat(
    #                 (combined_labels_old, labels), dim=0)

    #         vgg_feat_ds = TensorDataset(vgg_feat, vgg_labels)
    #         resnet_feat_ds = TensorDataset(resnet_feat, resnet_labels)
    #         combined_feat_ds = TensorDataset(combined_feat, combined_labels)

    #     # TODO: val stop here?
    #     # PCA 90%
    #     print('start pca...')
    #     vgg_feat_old, vgg_labels_old = vgg_feat_ds.tensors
    #     resnet_feat_old, resnet_labels_old = resnet_feat_ds.tensors
    #     combined_feat_old, combined_labels_old = combined_feat_ds.tensors

    #     vgg_feat_new = pca(vgg_feat_old.cpu(), 0.9)
    #     resnet_feat_new = pca(resnet_feat_old.cpu(), 0.9)
    #     combined_feat_new = pca(combined_feat_old.cpu(), 0.9)
    #     print('end pca...')

    #     if mode == 'train':
    #         vgg_feat_train = vgg_feat_new.numpy()
    #         vgg_labels_train = vgg_labels_old.numpy()
    #         resnet_feat_train = resnet_feat_new.numpy()
    #         resnet_labels_train = resnet_labels_old.numpy()
    #         combined_feat_train = combined_feat_new.numpy()
    #         combined_labels_train = combined_labels_old.numpy()
    #         print('Finish train mode feature extract')

    #         print('Start training SVM...')  # REMOVE: debug
    #         vgg_svm_model.fit(vgg_feat_train, vgg_labels_train)
    #         resnet_svm_model.fit(resnet_feat_train, resnet_labels_train)
    #         combined_svm_model.fit(combined_feat_train, combined_labels_train)
    #         print('Finish training SVM...')  # REMOVE: debug

    #     else:  # mode == 'val'
    #         vgg_feat_ds = TensorDataset(vgg_feat_new, vgg_labels_old)
    #         resnet_feat_ds = TensorDataset(resnet_feat_new, resnet_labels_old)
    #         combined_feat_ds = TensorDataset(
    #             combined_feat_new, combined_labels_old)

    #         vgg_feat_val_dl = DataLoader(
    #             vgg_feat_ds, batch_size=batch_size, num_workers=num_workers)
    #         resnet_feat_val_dl = DataLoader(
    #             resnet_feat_ds, batch_size=batch_size, num_workers=num_workers)
    #         combined_feat_val_dl = DataLoader(
    #             combined_feat_ds, batch_size=batch_size, num_workers=num_workers)
    #         print('Finish val mode feature extract')

    # # remove hook
    # vgg_handle.remove()
    # resnet_handle.remove()

    # train CNN
    criterion = torch.nn.CrossEntropyLoss()
    optimizer_vgg = torch.optim.SGD(
        vgg_model.parameters(), lr=learning_rate, momentum=alpha, weight_decay=lambd)
    optimizer_resnet = torch.optim.SGD(
        resnet_model.parameters(), lr=learning_rate, momentum=alpha, weight_decay=lambd)

    # TODO: loss same 1.791
    print('Start training VGG...')  # REMOVE: debug
    torch.cuda.empty_cache()
    train_cnn(train_loader, vgg_model, optimizer_vgg,
              criterion, num_epochs)
    torch.cuda.empty_cache()
    print('Start training ResNet...')  # REMOVE: debug
    train_cnn(train_loader, resnet_model,
              optimizer_resnet, criterion, num_epochs)

    # eval
    print('Start evaluating...')  # REMOVE: debug
    err = 0.0
    tot = 0.0
    for i, (inputs, labels) in enumerate(val_loader, 0):
        vgg_pred = predict(inputs, vgg_model)
        resnet_pred = predict(inputs, resnet_model)

        # (vgg_svm_inputs, _) = next(itertools.islice(vgg_feat_val_dl, i, None))
        # (resnet_svm_inputs, _) = next(
        #     itertools.islice(resnet_feat_val_dl, i, None))
        # (combined_svm_inputs, _) = next(
        #     itertools.islice(combined_feat_val_dl, i, None))

        # vgg_svm_pred = softmax(vgg_svm_model.predict(vgg_svm_inputs.numpy()), dim=1).to(
        #     device)  # TODO: all rows are same?
        # resnet_svm_pred = softmax(resnet_svm_model.predict(
        #     resnet_svm_inputs.numpy()), dim=1).to(device)
        # combined_svm_pred = softmax(combined_svm_model.predict(
        #     combined_svm_inputs.numpy()), dim=1).to(device)

        # ensemble_pred = (vgg_pred + resnet_pred + vgg_svm_pred +
        #                  resnet_svm_pred + combined_svm_pred)/5
        ensemble_pred = (vgg_pred + resnet_pred)/2
        pred_labels = torch.argmax(ensemble_pred, dim=1)

        labels = labels.to(device)
        err += sum(pred_labels != labels).item()
        tot += len(labels)
        loss = err/tot
        print(f'loss: {loss}. [{err}]/[{tot}]')
    print('Finish Evaluation')


# if __name__ == "__main__":
#     try:
#         main()
#     except KeyboardInterrupt:
#         pdb.set_trace()
