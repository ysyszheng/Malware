from config.config import device, config
from models.SVMModel import SVM  # TODO: use one-vs-all?
from models.VGGModel import VGG16
from models.ResNetModel import ResNet50
from utils.pca import pca
from torchvision import transforms
import torch
import torchvision
from torch.utils.data import TensorDataset, DataLoader, random_split
from PIL import Image
from tqdm import tqdm
import itertools
Image.MAX_IMAGE_PIXELS = None

vgg_feat_list = []
resnet_feat_list = []


def vgg_hook(module, input, output):
    vgg_feat_list.append(output)


def resnet_hook(module, input, output):
    resnet_feat_list.append(output)


def train_cnn(train_loader, model, optimizer, criterion, num_epochs):
    model.train()
    for epoch in range(num_epochs):
        running_loss = 0.0
        for (inputs, labels) in tqdm(train_loader, 0):
            inputs, labels = inputs.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(inputs)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            running_loss += loss.item()
        print('Epoch [%d]/[%d], loss: %.3f' %
              (epoch + 1, num_epochs, running_loss / len(train_loader)))
    print('Finished Training')


def predict(inputs, model):
    model.eval()
    model.to(device)
    inputs.to(device)
    with torch.no_grad:
        outputs = model(inputs)
    pr = torch.nn.functional.softmax(outputs, dim=1)
    return pr


if __name__ == "__main__":
    # transform and augment
    data_transforms = {  # TODO: try diff transform
        'train': transforms.Compose([
            transforms.Resize(256),
            transforms.CenterCrop(224),
            transforms.ToTensor(),
            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[
                0.229, 0.224, 0.225]),
        ]),
        'val': transforms.Compose([
            transforms.Resize(256),
            transforms.CenterCrop(224),
            transforms.ToTensor(),
            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])
        ]),
    }

    # config info
    batch_size = config['batch_size']
    learning_rate = config['learning_rate']
    alpha = config['momentum']
    lambd = config['weight_decay']
    num_epochs = config['num_epochs']
    num_workers = config['num_workers']
    num_class = config['num_class']
    split_rate = config['split_rate']
    data_path = config['img_path']

    # dataset and dataloader
    dataset = torchvision.datasets.ImageFolder(
        root=data_path, transform=data_transforms['train'])  # TODO: diff transform for diff model?

    train_size = int(config['split_rate'] * len(dataset))
    val_size = len(dataset) - train_size
    train_dataset, val_dataset = random_split(
        dataset, [train_size, val_size])

    train_loader = DataLoader(
        train_dataset, batch_size=batch_size, shuffle=True, num_workers=num_workers)
    val_loader = DataLoader(
        val_dataset, batch_size=batch_size, num_workers=num_workers)

    # cnn model define
    vgg_model = VGG16(num_class)
    resnet_model = ResNet50(num_class)

    # register hook
    vgg_handle = vgg_model.vgg.classifier[3].register_forward_hook(
        vgg_hook)  # TODO: is this FC2 layer?
    resnet_handle = resnet_model.resnet.avgpool.register_forward_hook(
        resnet_hook)

    # get SVM feature
    for mode in ['train', 'val']:
        loader = train_loader if mode == 'train' else val_loader

        # vgg_feat_ds = TensorDataset()
        # resnet_feat_ds = TensorDataset()
        # combined_feat_ds = TensorDataset()

        for i, (inputs, labels) in enumerate(loader, 0):
            vgg_model.eval()
            resnet_model.eval()
            vgg_model.to(device)
            resnet_model.to(device)
            inputs.to(device)

            with torch.no_grad():
                vgg_output = vgg_model(inputs)
                vgg_feat_new = vgg_feat_list.pop().squeeze()
                resnet_output = resnet_model(inputs)
                resnet_feat_new = resnet_feat_list.pop().squeeze()

            combined_feat_new = torch.cat(
                (vgg_feat_new, resnet_feat_new), dim=1)

            if i != 0:
                vgg_feat_old, vgg_labels_old = vgg_feat_ds.tensors
                resnet_feat_old, resnet_labels_old = resnet_feat_ds.tensors
                combined_feat_old, combined_labels_old = combined_feat_ds.tensors

                vgg_feat = torch.cat((vgg_feat_old, vgg_feat_new), dim=0)
                vgg_labels = torch.cat((vgg_labels_old, labels), dim=0)
                resnet_feat = torch.cat((resnet_feat_old, resnet_feat_new), dim=0)
                resnet_labels = torch.cat((resnet_labels_old, labels), dim=0)
                combined_feat = torch.cat(
                    (combined_feat_old, combined_feat_new), dim=0)
                combined_labels = torch.cat((combined_labels_old, labels), dim=0)
            else:
                vgg_feat, vgg_labels = vgg_feat_new, labels
                resnet_feat, resnet_labels = resnet_feat_new, labels
                combined_feat, combined_labels = combined_feat_new, labels


            vgg_feat_ds = TensorDataset(vgg_feat, vgg_labels)
            resnet_feat_ds = TensorDataset(resnet_feat, resnet_labels)
            combined_feat_ds = TensorDataset(combined_feat, combined_labels)

        # PCA 90%
        vgg_feat_old, vgg_labels_old = vgg_feat_ds.tensors
        resnet_feat_old, resnet_labels_old = resnet_feat_ds.tensors
        combined_feat_old, combined_labels_old = combined_feat_ds.tensors

        vgg_feat_new = pca(vgg_feat_old, 0.9)
        resnet_feat_new = pca(resnet_feat_old, 0.9)
        combined_feat_new = pca(combined_feat_old, 0.9)

        vgg_feat_ds = TensorDataset(vgg_feat_new, vgg_labels_old)
        resnet_feat_ds = TensorDataset(resnet_feat_new, resnet_labels_old)
        combined_feat_ds = TensorDataset(
            combined_feat_new, combined_labels_old)

        if mode == 'train':
            vgg_feat_train_dl = DataLoader(
                vgg_feat_ds, batch_size=batch_size, shuffle=True, num_workers=num_workers)
            resnet_feat_train_dl = DataLoader(
                resnet_feat_ds, batch_size=batch_size, shuffle=True, num_workers=num_workers)
            combined_feat_train_dl = DataLoader(
                combined_feat_ds, batch_size=batch_size, shuffle=True, num_workers=num_workers)
        elif mode == 'val':
            vgg_feat_val_dl = DataLoader(
                vgg_feat_ds, batch_size=batch_size, num_workers=num_workers)
            resnet_feat_val_dl = DataLoader(
                resnet_feat_ds, batch_size=batch_size, num_workers=num_workers)
            combined_feat_val_dl = DataLoader(
                combined_feat_ds, batch_size=batch_size, num_workers=num_workers)

    # remove hook
    vgg_handle.remove()
    resnet_handle.remove()

    # defnine svm model TODO: calculate input size from feat (after pca) shape
    vgg_svm_model = SVM(num_class, 410).to(device)
    resnet_svm_model = SVM(num_class, 205).to(device)
    combined_svm_model = SVM(num_class, 615).to(device)

    # train SVM
    vgg_svm_model.fit(vgg_feat_train_dl, num_epochs, learning_rate)
    resnet_svm_model.fit(resnet_feat_train_dl, num_epochs, learning_rate)
    combined_svm_model.fit(combined_feat_train_dl, num_epochs, learning_rate)

    # train CNN
    criterion = torch.nn.CrossEntropyLoss()
    optimizer_vgg = torch.optim.SGD(
        vgg_model.parameters(), lr=learning_rate, momentum=alpha, weight_decay=lambd)
    optimizer_resnet = torch.optim.SGD(
        resnet_model.parameters(), lr=learning_rate, momentum=alpha, weight_decay=lambd)

    train_cnn(train_loader, vgg_model, optimizer_vgg, criterion, num_epochs)
    train_cnn(train_loader, resnet_model,
              optimizer_resnet, criterion, num_epochs)

    # eval
    err = 0.0
    tot = 0.0
    for i, (inputs, labels) in enumerate(val_loader, 0):
        vgg_pred = predict(inputs, vgg_model)
        resnet_pred = predict(inputs, resnet_model)

        # TODO: check svm inputs, is shuffled?
        (vgg_svm_inputs, _) = next(itertools.islice(vgg_feat_val_dl, i, None))
        (resnet_svm_inputs, _) = next(
            itertools.islice(resnet_feat_val_dl, i, None))
        (combined_svm_inputs, _) = next(
            itertools.islice(combined_feat_val_dl, i, None))

        vgg_svm_pred = predict(vgg_svm_inputs, vgg_svm_model)
        resnet_svm_pred = predict(resnet_svm_inputs, resnet_svm_model)
        combined_svm_pred = predict(combined_svm_inputs, combined_svm_model)

        ensemble_pred = vgg_pred + resnet_pred + vgg_svm_pred + \
            resnet_svm_pred + combined_svm_pred  # TODO: how to add
        pred_labels = torch.argmax(ensemble_pred, dim=1)
        
        err += torch.sum(pred_labels == labels).item()
        tot += len(labels)
        loss = err/tot
        print(f'loss: {loss}')
    print('Finish Evaluation')
