import torch
import numpy as np
from tqdm import tqdm
from config.cfgs import cfgs
from models.cnnmodels import VGG16, ResNet50
from utils.utils import fix_seed
from utils.data_loader import get_data_loaders


class Trainer(object):
    def __init__(self, cfgs):
        fix_seed(cfgs['seed'])
        self.cfgs = cfgs
        self.device = f'cuda:{cfgs["cuda_idx"]}' if torch.cuda.is_available() else 'cpu'
        self.model = VGG16(num_classes=cfgs["num_classes"])
        self.optimizer = torch.optim.SGD(self.model.parameters(), lr=cfgs["learning_rate"], 
                        momentum=cfgs['momentum'], weight_decay=cfgs['weight_decay'])
        self.criterion = torch.nn.CrossEntropyLoss()
        self.dataloaders = dict()

    def training(self):
        self.model.train()
        self.model.to(self.device)
        self.dataloaders['train'], self.dataloaders['val'] = get_data_loaders(cfgs['img_gray_path'], cfgs['seed'], 
                batch_size=cfgs['batch_size'], train_ratio=cfgs['split_ratio'], num_workers=cfgs['num_workers'])
        train_loss_list = []
        val_loss_list = []
        train_acc_list = []
        val_acc_list = []

        progress_bar = tqdm(range(1, self.cfgs['num_epochs']+1))
        for epoch in progress_bar:
            for phase in ['train', 'val']:
                if phase == 'train':
                    self.model.train()
                else:
                    self.model.eval()

                running_loss = 0.0
                running_corrects = 0

                for inputs, labels in self.dataloaders[phase]:
                    inputs, labels = inputs.to(self.device), labels.to(self.device)

                    self.optimizer.zero_grad()

                    with torch.set_grad_enabled(phase == 'train'):
                        outputs = self.model(inputs)
                        loss = self.criterion(outputs, labels)

                        _, preds = torch.max(outputs, 1)

                        if phase == 'train':
                            loss.backward()
                            self.optimizer.step()

                    running_loss += loss.item() * inputs.size(0)
                    running_corrects += torch.sum(preds == labels.data).cpu().numpy()

                epoch_loss = running_loss / len(self.dataloaders[phase].dataset)
                epoch_acc = running_corrects / len(self.dataloaders[phase].dataset)
                progress_bar.set_description(
                    f'Epoch {epoch}, {phase} loss: {epoch_loss:.4f}, {phase} accuracy: {epoch_acc:.4f}')

                if phase == 'train':
                    train_loss_list.append(epoch_loss)
                    train_acc_list.append(epoch_acc)
                else:
                    val_loss_list.append(epoch_loss)
                    val_acc_list.append(epoch_acc)

            if epoch % cfgs['save_freq'] == 0:
                torch.save(self.model.state_dict(), f'{cfgs["save_model_path"]}/vgg_{epoch}.pth')
                np.save(f'{cfgs["save_data_path"]}/vgg_train_loss_{epoch}.npy', train_loss_list)
                np.save(f'{cfgs["save_data_path"]}/vgg_val_loss_{epoch}.npy', val_loss_list)
                np.save(f'{cfgs["save_data_path"]}/vgg_train_acc_{epoch}.npy', train_acc_list)
                np.save(f'{cfgs["save_data_path"]}/vgg_val_acc_{epoch}.npy', val_acc_list)


    def validating(self):
        self.model.load_state_dict(torch.load(f'{cfgs["save_model_path"]}/vgg_50.pth'))
        self.model.eval()
        correct_predictions = 0

        with torch.no_grad():
            for inputs, labels in self.dataloaders['val']:
                inputs, labels = inputs.to(self.device), labels.to(self.device)

                outputs = self.model(inputs)
                _, predictions = torch.max(outputs, 1)

                correct_predictions += torch.sum(predictions == labels.data)

        accuracy = correct_predictions.double() / len(self.dataloaders['val'].dataset)
        print(accuracy.item())
        