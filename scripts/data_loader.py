'''load data from image dir for training and validation'''
import os
import random
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from PIL import Image
Image.MAX_IMAGE_PIXELS = None


def get_data_loaders(data_dir, batch_size=32, train_ratio=0.7, num_workers=4):
    """
    Returns train and validation data loaders for the given data directory.
    """
    data_transforms = {
        'train': transforms.Compose([
            transforms.RandomResizedCrop(224),
            transforms.RandomHorizontalFlip(),
            transforms.ToTensor(),
            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])
        ]),
        'val': transforms.Compose([
            transforms.Resize(256),
            transforms.CenterCrop(224),
            transforms.ToTensor(),
            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])
        ]),
    }

    class_folders = sorted(os.listdir(data_dir))
    class_folders = [os.path.join(data_dir, folder) for folder in class_folders]

    train_data = []
    val_data = []
    for folder in class_folders:
        images = random.shuffle(os.listdir(folder))
        num_train = int(len(images) * train_ratio)
        train_data += [(os.path.join(folder, image), idx) for idx, image in enumerate(images[:num_train])]
        val_data += [(os.path.join(folder, image), idx) for idx, image in enumerate(images[num_train:])]

    random.shuffle(train_data)
    random.shuffle(val_data)

    train_dataset = datasets.ImageFolder(train_data, data_transforms['train'])
    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=num_workers)

    val_dataset = datasets.ImageFolder(val_data, data_transforms['val'])
    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=num_workers)

    return train_loader, val_loader
