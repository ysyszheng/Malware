import torch
import torch.nn as nn
import torchvision.transforms as transforms
import torch.optim as optim


class SimCLRModel(nn.Module):
    def __init__(self, base_encoder, projection_dim=128):
        super(SimCLRModel, self).__init__()
        self.base_encoder = base_encoder
        self.projection_head = nn.Sequential(
            nn.Linear(in_features=base_encoder.fc.in_features, out_features=projection_dim),
            nn.ReLU(),
            nn.Linear(in_features=projection_dim, out_features=projection_dim)
        )

    def forward(self, x):
        features = self.base_encoder(x)
        return self.projection_head(features)


def train_simclr(model, data_loader, criterion, optimizer, device):
    model.train()
    loss_epoch = 0.0
    for images, _ in data_loader:
        images = images.to(device)

        transform = transforms.Compose([
            transforms.RandomHorizontalFlip(),
            transforms.RandomResizedCrop(224, scale=(0.08, 1.0)),
            transforms.ToTensor(),
        ])

        images_aug = torch.stack([transform(img) for img in images])

        optimizer.zero_grad()

        features = model(images_aug)

        # 计算 SimCLR loss
        batch_size = images.size(0)
        labels = torch.arange(batch_size, device=device)
        labels = torch.cat([labels, labels], dim=0)
        logits = torch.div(torch.matmul(features, features.T), 0.07)
        loss = criterion(logits, labels)

        loss.backward()
        optimizer.step()

        loss_epoch += loss.item()

    return loss_epoch