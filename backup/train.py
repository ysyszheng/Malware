from config.config import device, data_transforms, config
from models.svmmodels import OvASVM
from models.cnnmodels import VGG16, ResNet50
from utils.pca import pca
import torch
import numpy as np
import pdb
import torchvision
from torch.utils.data import TensorDataset, DataLoader, random_split
from torch.nn.functional import softmax
from PIL import Image
from tqdm import tqdm
import itertools
Image.MAX_IMAGE_PIXELS = None


def train_cnn(train_loader, model, optimizer, criterion, num_epochs):
    model.train()
    model.to(device)

    for epoch in range(num_epochs):
        running_loss = 0.0
        for (inputs, labels) in tqdm(train_loader):
            inputs, labels = inputs.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(inputs)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            running_loss += loss.item()
        print('Epoch [%d]/[%d], loss: %.3f' %
              (epoch + 1, num_epochs, running_loss / len(train_loader)))
    print('Finished Training')


def predict(inputs, model):
    model.eval()
    model.to(device)
    inputs = inputs.to(device)
    with torch.no_grad():
        outputs = model(inputs)
    pr = softmax(outputs, dim=1)
    return pr


if __name__ == "__main__":
    # config info
    batch_size = config['batch_size']
    learning_rate = config['learning_rate']
    alpha = config['momentum']
    lambd = config['weight_decay']
    num_epochs = config['num_epochs']
    num_workers = config['num_workers']
    num_class = config['num_class']
    split_rate = config['split_rate']
    data_path = config['img_path']

    # dataset and dataloader
    dataset = torchvision.datasets.ImageFolder(
        root=data_path, transform=None)

    train_size = int(config['split_rate'] * len(dataset))
    val_size = len(dataset) - train_size
    train_dataset, val_dataset = random_split(
        dataset, [train_size, val_size])
    train_dataset.dataset.transform = data_transforms['train']
    val_dataset.dataset.transform = data_transforms['val']

    train_loader = DataLoader(
        train_dataset, batch_size=batch_size, shuffle=True, num_workers=num_workers)
    val_loader = DataLoader(
        val_dataset, batch_size=batch_size, num_workers=num_workers)

    # model
    vgg_model = VGG16(num_class)
    resnet_model = ResNet50(num_class)

    # train CNN
    criterion = torch.nn.CrossEntropyLoss()
    optimizer_vgg = torch.optim.SGD(
        vgg_model.parameters(), lr=learning_rate, momentum=alpha, weight_decay=lambd)
    optimizer_resnet = torch.optim.SGD(
        resnet_model.parameters(), lr=learning_rate, momentum=alpha, weight_decay=lambd)

    print('Start training VGG')
    train_cnn(train_loader, vgg_model, optimizer_vgg,
              criterion, num_epochs)
    
    print('Start training ResNet')
    train_cnn(train_loader, resnet_model,
              optimizer_resnet, criterion, num_epochs)

    # eval
    print('Start evaluating')
    err = 0.0
    tot = 0.0
    for i, (inputs, labels) in enumerate(val_loader, 0):
        vgg_pred = predict(inputs, vgg_model)
        resnet_pred = predict(inputs, resnet_model)

        ensemble_pred = (vgg_pred + resnet_pred)/2
        pred_labels = torch.argmax(ensemble_pred, dim=1)

        labels = labels.to(device)
        err += sum(pred_labels != labels).item()
        tot += len(labels)
        loss = err/tot
        print(f'loss: {loss}. [{err}]/[{tot}]')
    print('Finish Evaluation')
